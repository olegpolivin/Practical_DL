{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Homework 2.2: The Quest For A Better Network\n",
    "\n",
    "In this assignment you will build a monster network to solve Tiny ImageNet image classification.\n",
    "\n",
    "This notebook is intended as a sequel to seminar 3, please give it a try if you haven't done so yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(please read it at least diagonally)\n",
    "\n",
    "* The ultimate quest is to create a network that has as high __accuracy__ as you can push it.\n",
    "* There is a __mini-report__ at the end that you will have to fill in. We recommend reading it first and filling it while you iterate.\n",
    " \n",
    "## Grading\n",
    "* starting at zero points\n",
    "* +20% for describing your iteration path in a report below.\n",
    "* +20% for building a network that gets above 20% accuracy\n",
    "* +10% for beating each of these milestones on __TEST__ dataset:\n",
    "    * 25% (50% points)\n",
    "    * 30% (60% points)\n",
    "    * 32.5% (70% points)\n",
    "    * 35% (80% points)\n",
    "    * 37.5% (90% points)\n",
    "    * 40% (full points)\n",
    "    \n",
    "## Restrictions\n",
    "* Please do NOT use pre-trained networks for this assignment until you reach 40%.\n",
    " * In other words, base milestones must be beaten without pre-trained nets (and such net must be present in the anytask atttachments). After that, you can use whatever you want.\n",
    "* you __can't__ do anything with validation data apart from running the evaluation procedure. Please, split train images on train and validation parts\n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    " * __Network size__\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, ([torch.nn docs](http://pytorch.org/docs/master/nn.html))\n",
    "\n",
    "   * Nonlinearities in the hidden layers\n",
    "     * tanh, relu, leaky relu, etc\n",
    "   * Larger networks may take more epochs to train, so don't discard your net just because it could didn't beat the baseline in 5 epochs.\n",
    "\n",
    "   * Ph'nglui mglw'nafh Cthulhu R'lyeh wgah'nagl fhtagn!\n",
    "\n",
    "\n",
    "### The main rule of prototyping: one change at a time\n",
    "   * By now you probably have several ideas on what to change. By all means, try them out! But there's a catch: __never test several new things at once__.\n",
    "\n",
    "\n",
    "### Optimization\n",
    "   * Training for 100 epochs regardless of anything is probably a bad idea.\n",
    "   * Some networks converge over 5 epochs, others - over 500.\n",
    "   * Way to go: stop when validation score is 10 iterations past maximum\n",
    "   * You should certainly use adaptive optimizers\n",
    "     * rmsprop, nesterov_momentum, adam, adagrad and so on.\n",
    "     * Converge faster and sometimes reach better optima\n",
    "     * It might make sense to tweak learning rate/momentum, other learning parameters, batch size and number of epochs\n",
    "   * __BatchNormalization__ (nn.BatchNorm2d) for the win!\n",
    "     * Sometimes more batch normalization is better.\n",
    "   * __Regularize__ to prevent overfitting\n",
    "     * Add some L2 weight norm to the loss function, PyTorch will do the rest\n",
    "       * Can be done manually or like [this](https://discuss.pytorch.org/t/simple-l2-regularization/139/2).\n",
    "     * Dropout (`nn.Dropout`) - to prevent overfitting\n",
    "       * Don't overdo it. Check if it actually makes your network better\n",
    "   \n",
    "### Convolution architectures\n",
    "   * This task __can__ be solved by a sequence of convolutions and poolings with batch_norm and ReLU seasoning, but you shouldn't necessarily stop there.\n",
    "   * [Inception family](https://hacktilldawn.com/2016/09/25/inception-modules-explained-and-implemented/), [ResNet family](https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035?gi=9018057983ca), [Densely-connected convolutions (exotic)](https://arxiv.org/abs/1608.06993), [Capsule networks (exotic)](https://arxiv.org/abs/1710.09829)\n",
    "   * Please do try a few simple architectures before you go for resnet-152.\n",
    "   * Warning! Training convolutional networks can take long without GPU. That's okay.\n",
    "     * If you are CPU-only, we still recomment that you try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    "     * Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.\n",
    "     * __To reduce computation__ time by a factor in exchange for some accuracy drop, try using __stride__ parameter. A stride=2 convolution should take roughly 1/4 of the default (stride=1) one.\n",
    " \n",
    "   \n",
    "### Data augmemntation\n",
    "   * getting 5x as large dataset for free is a great \n",
    "     * Zoom-in+slice = move\n",
    "     * Rotate+zoom(to remove black stripes)\n",
    "     * Add Noize (gaussian or bernoulli)\n",
    "   * Simple way to do that (if you have PIL/Image): \n",
    "     * ```from scipy.misc import imrotate,imresize```\n",
    "     * and a few slicing\n",
    "     * Other cool libraries: cv2, skimake, PIL/Pillow\n",
    "   * A more advanced way is to use torchvision transforms:\n",
    "    ```\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "    trainset = torchvision.datasets.ImageFolder(root=path_to_tiny_imagenet, train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "    ```\n",
    "   * Or use this tool from Keras (requires theano/tensorflow): [tutorial](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), [docs](https://keras.io/preprocessing/image/)\n",
    "   * Stay realistic. There's usually no point in flipping dogs upside down as that is not the way you usually see them.\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import skimage\n",
    "from skimage import io\n",
    "from PIL import Image\n",
    "from torch.utils.data import SubsetRandomSampler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tiny_img import download_tinyImg200\n",
    "# data_path = '.'\n",
    "# download_tinyImg200(data_path)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomChoice(\n",
    "        [transforms.RandomRotation(5),\n",
    "         transforms.RandomHorizontalFlip(0.3),\n",
    "         transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n",
    "         transforms.RandomAffine(2, scale=(1,1.3))]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.ImageFolder('tiny-imagenet-200/train', transform=transform_train)\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [80000, 20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we'll need this later, when testing the model at the end\n",
    "class_to_idx = dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_sampler = SubsetRandomSampler(train_dataset.indices)\n",
    "val_sampler = SubsetRandomSampler(val_dataset.indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=True,\n",
    "                            num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential()\n",
    "\n",
    "model.add_module('conv1', nn.Conv2d(3, 200, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn1_1', nn.BatchNorm2d(200))\n",
    "model.add_module('relu1_1', nn.ReLU())\n",
    "model.add_module('conv1_2', nn.Conv2d(200, 200, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn1_2', nn.BatchNorm2d(200))\n",
    "model.add_module('relu1_2', nn.ReLU())\n",
    "model.add_module('maxpool1', nn.MaxPool2d(3))\n",
    "\n",
    "model.add_module('conv2_1', nn.Conv2d(200, 400, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn2_1', nn.BatchNorm2d(400))\n",
    "model.add_module('relu2_1', nn.ReLU())\n",
    "model.add_module('conv2_2', nn.Conv2d(400, 400, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn2_2', nn.BatchNorm2d(400))\n",
    "model.add_module('relu2_2', nn.ReLU())\n",
    "model.add_module('maxpool2', nn.MaxPool2d(3))\n",
    "\n",
    "model.add_module('flatten', nn.Flatten())\n",
    "model.add_module('fc1', nn.Linear(10000, 1000))\n",
    "model.add_module('dp1', nn.Dropout(0.5))\n",
    "model.add_module('fc2', nn.Linear(1000, 200))\n",
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "#L2 regularization is added through weight_decay\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, weight_decay=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, optimizer, num_epochs, scheduler = None):\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        model.train(True)\n",
    "        start_time = time.time()\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            \n",
    "            # I. Training\n",
    "            #1 Train on GPU\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            \n",
    "            #2 Clear the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #3 Forward\n",
    "            predictions = model.forward(x_batch)\n",
    "            \n",
    "            #4 Calculating loss\n",
    "            loss = loss_fn(predictions, y_batch)\n",
    "            \n",
    "            #5 Calculating gradients\n",
    "            loss.backward()\n",
    "\n",
    "            #6 Optimizer step\n",
    "            optimizer.step()\n",
    "            \n",
    "            # II. Tracking the training\n",
    "            train_loss.append(loss.cpu().data.numpy())  \n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        # III. Validation\n",
    "        model.train(False) # disable dropout / use averages for batch_norm\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "            predictions = model.forward(x_batch)\n",
    "            y_pred = predictions.max(1)[1].data\n",
    "            val_accuracy.append(np.mean( (y_batch.cpu() == y_pred.cpu()).numpy() ))\n",
    "        \n",
    "        validation_accuracy = np.mean(val_accuracy[-len(val_dataset) // batch_size :]) * 100\n",
    "        # IV. Reporting\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, num_epochs, time.time() - start_time))\n",
    "        print(\"  training loss (in-iteration): \\t{:.6f}\".format(\n",
    "            np.mean(train_loss[-len(train_dataset) // batch_size :])))\n",
    "        print(\"  validation accuracy: \\t\\t\\t{:.2f} %\".format(\n",
    "            validation_accuracy))\n",
    "        \n",
    "        if validation_accuracy > 40:\n",
    "            print(f'Fitted the model to exceed 40% on the validation set.Exiting loop on epoch {epoch}.')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 100 took 109.162s\n",
      "  training loss (in-iteration): \t4.654612\n",
      "  validation accuracy: \t\t\t14.59 %\n",
      "Epoch 2 of 100 took 109.329s\n",
      "  training loss (in-iteration): \t3.920082\n",
      "  validation accuracy: \t\t\t20.14 %\n",
      "Epoch 3 of 100 took 109.387s\n",
      "  training loss (in-iteration): \t3.606608\n",
      "  validation accuracy: \t\t\t23.89 %\n",
      "Epoch 4 of 100 took 109.428s\n",
      "  training loss (in-iteration): \t3.388545\n",
      "  validation accuracy: \t\t\t27.09 %\n",
      "Epoch 5 of 100 took 109.625s\n",
      "  training loss (in-iteration): \t3.224967\n",
      "  validation accuracy: \t\t\t28.96 %\n",
      "Epoch 6 of 100 took 109.388s\n",
      "  training loss (in-iteration): \t3.086675\n",
      "  validation accuracy: \t\t\t30.04 %\n",
      "Epoch 7 of 100 took 109.595s\n",
      "  training loss (in-iteration): \t2.965666\n",
      "  validation accuracy: \t\t\t31.13 %\n",
      "Epoch 8 of 100 took 109.481s\n",
      "  training loss (in-iteration): \t2.854407\n",
      "  validation accuracy: \t\t\t33.02 %\n",
      "Epoch 9 of 100 took 109.745s\n",
      "  training loss (in-iteration): \t2.753513\n",
      "  validation accuracy: \t\t\t32.06 %\n",
      "Epoch 10 of 100 took 109.453s\n",
      "  training loss (in-iteration): \t2.661472\n",
      "  validation accuracy: \t\t\t34.26 %\n",
      "Epoch 11 of 100 took 109.477s\n",
      "  training loss (in-iteration): \t2.561530\n",
      "  validation accuracy: \t\t\t34.29 %\n",
      "Epoch 12 of 100 took 109.730s\n",
      "  training loss (in-iteration): \t2.470304\n",
      "  validation accuracy: \t\t\t35.66 %\n",
      "Epoch 13 of 100 took 109.668s\n",
      "  training loss (in-iteration): \t2.380592\n",
      "  validation accuracy: \t\t\t35.36 %\n",
      "Epoch 14 of 100 took 109.663s\n",
      "  training loss (in-iteration): \t2.298868\n",
      "  validation accuracy: \t\t\t36.07 %\n",
      "Epoch 15 of 100 took 109.695s\n",
      "  training loss (in-iteration): \t2.207569\n",
      "  validation accuracy: \t\t\t37.67 %\n",
      "Epoch 16 of 100 took 109.504s\n",
      "  training loss (in-iteration): \t1.860624\n",
      "  validation accuracy: \t\t\t39.87 %\n",
      "Epoch 17 of 100 took 109.905s\n",
      "  training loss (in-iteration): \t1.788002\n",
      "  validation accuracy: \t\t\t40.09 %\n",
      "Fitted the model to exceed 40% on the validation set.Exiting loop on epoch 16.\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_accuracy = []\n",
    "train_model(model, train_loader, val_loader, optimizer, 100, scheduler = scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'cumbersome_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feel free to copypaste code from seminar03 as a basic template for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When everything is done, please calculate accuracy on `tiny-imagenet-200/val`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('tiny-imagenet-200/val/val_annotations.txt', sep='\\t', header=None)\n",
    "labels.columns = ['imname', 'id', 'bb1', 'bb2', 'bb3', 'bb4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_folder, labels_frame, class_to_idx, transform=None):\n",
    "\n",
    "        self.transform = transform\n",
    "        self.root_folder = root_folder\n",
    "        self.labels_frame = labels_frame\n",
    "        self.class_to_idx = class_to_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_frame) - 1\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        img_name = os.path.join(self.root_folder,\n",
    "                                self.labels_frame.loc[idx, 'imname'])\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        # Treating greyscale images\n",
    "        if len(image.shape) < 3:\n",
    "            image = skimage.color.grey2rgb(image, alpha=None)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        category = self.class_to_idx[self.labels_frame.loc[idx, 'id']]\n",
    "        return image, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(root_folder='tiny-imagenet-200/val/images/',\n",
    "                           labels_frame=labels,\n",
    "                           class_to_idx=class_to_idx,\n",
    "                           transform = transforms.Compose([\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                           ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                            batch_size=10,\n",
    "                            shuffle=True,\n",
    "                            num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(False)\n",
    "correct_samples = 0\n",
    "total_samples = 0\n",
    "for x_batch, y_batch in test_loader:\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "    predictions = model.forward(x_batch)\n",
    "    y_pred = predictions.max(1)[1].data\n",
    "    correct_samples += torch.sum(y_pred == y_batch)\n",
    "    total_samples += y_batch.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy = float(correct_samples) / total_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t42.07 %\n",
      "Achievement unlocked: 110lvl Warlock!\n"
     ]
    }
   ],
   "source": [
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_accuracy * 100))\n",
    "\n",
    "if test_accuracy * 100 > 40:\n",
    "    print(\"Achievement unlocked: 110lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 35:\n",
    "    print(\"Achievement unlocked: 80lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 30:\n",
    "    print(\"Achievement unlocked: 70lvl Warlock!\")\n",
    "elif test_accuracy * 100 > 25:\n",
    "    print(\"Achievement unlocked: 60lvl Warlock!\")\n",
    "else:\n",
    "    print(\"We need more magic! Follow instructons below\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "# Report\n",
    "\n",
    "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
    "* the idea;\n",
    "* brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method and, again, why?\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "\n",
    "There is no need to write strict mathematical proofs (unless you want to).\n",
    " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
    " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
    " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `Oleg Polivin`, and here's my story\n",
    "\n",
    "A long time ago in a galaxy far far away, when it was still more than an hour before the deadline, i got an idea:\n",
    "\n",
    "##### I gonna build a neural network, that\n",
    "Includes several convolutional layers followed by non-linearities, and in the end by some fully-connected layers, so that in the end it would be possible to apply softmax for 200 classes. However, I was a bit confused about the order in which batchnorms, non-linearities, maxpool and dropout layers shall be applied. Watching seminar 3 helped a lot: there Vika Checkalina explained well that BN is normally followed by ReLUs and not vice-versa. This helped to establish the structure in the network.\n",
    "\n",
    "Actually, I was not naive at all. My final architecture is not that different from where I started, but what is interesting is that about three days separate my first architecture from my last one. I did many experiments just to come back there where I started (all experiments gave worse results).\n",
    "\n",
    "##### One day, with no signs of warning,\n",
    "This thing has finally converged and\n",
    "* Some explaination about what were the results,\n",
    "\n",
    "Right in the beginning, I started to achieve accuracy close to 34%. And here is my first architecture:\n",
    "```\n",
    "model = nn.Sequential()\n",
    "model.add_module('conv1', nn.Conv2d(3, 200, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn1', nn.BatchNorm2d(200))\n",
    "model.add_module('relu1', nn.ReLU())\n",
    "model.add_module('maxpool1', nn.MaxPool2d(3))\n",
    "model.add_module('conv2', nn.Conv2d(200, 400, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn2', nn.BatchNorm2d(400))\n",
    "model.add_module('relu2', nn.ReLU())\n",
    "model.add_module('maxpool2', nn.MaxPool2d(3))\n",
    "model.add_module('flatten', nn.Flatten())\n",
    "model.add_module('fc1', nn.Linear(14400, 1000))\n",
    "model.add_module('fc2', nn.Linear(1000, 200))\n",
    "```\n",
    "\n",
    "* what worked and what didn't\n",
    "\n",
    " I was quite happy, and thought that it was an easy task. However, I could not increase the accuracy further. And then I told myself: look, it is stated in the homework that we should `Make reasonable layer size estimates. A 128-neuron first convolution is likely an overkill.` So I started trying smaller networks, but that contained more layers: I added Leaky ReLUs, Dropout between Linear layers, tried to make a network similar to VGG16 one, but it didn't help!!! Actually, I still don't understand well why. My idea was to start with not many `out_channels` in the first convolution layer, something like `16` or `32` and then increase further. But to no avail: networks were stuck at 5%, 10%, 15%, 25% accuracy, but didn't improve further.  I introduced scheduler with cosine annealing, with decrease every N epochs, but it didn't help neither. I was really confused. Why it didn't work, even when it resembled so closely the VGG16 network? I started adding augmentations, it helped, but still I couldn't get better than 32% in accuracy.\n",
    "\n",
    "Increasing the default Adam LR didn't help. \n",
    "Decreasing made the learning too slow.\n",
    "\n",
    "* most importantly - what next steps were taken, if any\n",
    "* and what were their respective outcomes\n",
    "\n",
    "By the third day I remembered that my first network, where I didn't try to reproduce VGG, actually, worked better than all my experiments so far. And the key moment was that it contained quite a large number of out channels in the first convolutional layer. I thought it contradicted the advice given in the beginning of the homework (about the overkill), but it gave the best results, so I decided to pursure that way. In the end, what worked:\n",
    "\n",
    "[-] having 200 out channels in the first convolution layer.\n",
    "\n",
    "[-] introducing data augmentations. Even not much (I have 4 to choose from, but apply only 1 to a given image), gave an increase in accuracy. Say, from 33-34% I went to 35-36%.\n",
    "\n",
    "[-] But how to increase more???\n",
    "\n",
    "[-] What helped me a lot in this stage, is the image of the VGG16 architecture that I was looking at. Understand, I was too used to architectures that either always increase or always decrease in the number of neurons/out channels. But VGG repeats some convolutions, in the sense that in channel number of filters = out channel number of filters. The same for the fully-connected layers. 4096 -> 4096 -> number of classes. I decided to dot it for my convolution layers, and it gave a great boost! \n",
    "\n",
    "These are the layers:\n",
    "\n",
    "[-] model.add_module('conv1_2', nn.Conv2d(200, 200, kernel_size=(3,3), stride=1))\n",
    "\n",
    "[-] model.add_module('conv2_2', nn.Conv2d(400, 400, kernel_size=(3,3), stride=1))\n",
    "\n",
    "It increased accuracy on the validation set to 39%. But I was stuck there! I wanted that accuracy on validation set goes over 40%! So the final part in the quest, was an introduction of the scheduler. A simple StepLR one, that decreases learning rate every 15 epochs ten times. \n",
    "\n",
    "With a very small boost of 1%, I started to get over 40% each time I started teaching the network.\n",
    "\n",
    "##### Finally, after ~1000  iterations, 15 mugs of tea and 15 mugs of coffee\n",
    "* what was the final architecture\n",
    "* as well as training method and tricks\n",
    "\n",
    "Here is the architecture:\n",
    "```\n",
    "model.add_module('conv1', nn.Conv2d(3, 200, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn1_1', nn.BatchNorm2d(200))\n",
    "model.add_module('relu1_1', nn.ReLU())\n",
    "model.add_module('conv1_2', nn.Conv2d(200, 200, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn1_2', nn.BatchNorm2d(200))\n",
    "model.add_module('relu1_2', nn.ReLU())\n",
    "model.add_module('maxpool1', nn.MaxPool2d(3))\n",
    "\n",
    "model.add_module('conv2_1', nn.Conv2d(200, 400, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn2_1', nn.BatchNorm2d(400))\n",
    "model.add_module('relu2_1', nn.ReLU())\n",
    "model.add_module('conv2_2', nn.Conv2d(400, 400, kernel_size=(3,3), stride=1))\n",
    "model.add_module('bn2_2', nn.BatchNorm2d(400))\n",
    "model.add_module('relu2_2', nn.ReLU())\n",
    "model.add_module('maxpool2', nn.MaxPool2d(3))\n",
    "\n",
    "model.add_module('flatten', nn.Flatten())\n",
    "model.add_module('fc1', nn.Linear(10000, 1000))\n",
    "model.add_module('dp1', nn.Dropout(0.5))\n",
    "model.add_module('fc2', nn.Linear(1000, 200))\n",
    "```\n",
    "\n",
    "So it heavily relies on convolution and maxpooling.\n",
    "Training methods and tricks were described above. Most important are using Adam as the gradient descent method + using data augmentations + repeating some convolutions in the sense that I added convolution filters that have in_channels = out_channels.\n",
    "\n",
    "That, having wasted 10 hours of my life training, got\n",
    "\n",
    "* accuracy on training: I didn't check it.\n",
    "* accuracy on validation: 40.09%\n",
    "* accuracy on test: 42.07%\n",
    "\n",
    "\n",
    "[an optional afterword and mortal curses on assignment authors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks a lot for the task!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
